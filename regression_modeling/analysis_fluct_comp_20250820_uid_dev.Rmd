---
title: "analysis_fluct_comp_20250820"
author: "Isabell Landwehr"
date: "2025-08-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## About

Mixed-effects (generalized) linear regression models for the UID measure UIDev (average of surprisal differences).

## Set up

```{r, warning=FALSE, message=FALSE}
# libraries
library(car)
library(DHARMa)
library(dplyr)
library(future.apply)
library(ggeffects)
library(ggplot2)
library(glmmTMB)
library(performance)
library(rsample)
```

## Load data

```{r}
# open data file
data <- read.table(file="C:/Users/isabell/Documents/UdS/Corpus_Analysis/RSC/fluctuation_complexity/data/NP_data_20250731.csv",
                   sep=",",
                   header=TRUE,
                   quote='"',
                   fill=TRUE)
head(data)
```

## Preprocessing

Filter data:
- remove observations whose head lemma occurs less than 5 times
- remove observations from after the year 1989
- remove observations without a sigma_gamma or uid_dev value

```{r}
# filter data
np_data <- data %>%
  group_by(head_lemma) %>% # remove observations with lemma occurrence >= 5
  filter(n() >= 5) %>%
  ungroup() %>%
  filter(year <= 1989) %>% # remove observations after 1989
  filter(!is.na(uid_dev)) %>% # remove observations without uid_dev value
  filter(!is.na(sigma_gamma)) # remove observations without sigma_gamma value
```

Transform variables:
- center year variable
- center NP length
- center average surprisal

```{r}
# transform year variable
np_data$year_c <- scale(np_data$year, center=T, scale=F)
# transform NP length variable
np_data$NP_len_c <- scale(np_data$NP_len, center=T, scale=F)
# transform average surprisal variable
np_data$avg_srp_c <- scale(np_data$avg_srp, center=T, scale=F)
```

Apply contrast coding:
- treatment coding for syntactic role: baseline = nsubj

```{r}
# transform syntactic role to factor
np_data$head_synt_role_F <- as.factor(np_data$head_synt_role)
levels(np_data$head_synt_role_F) # show factor levels
```
```{r}
# apply contrast coding
contrasts(np_data$head_synt_role_F) = contr.treatment(3, base=1) # baseline=nsubj
```

## Fit simple model

# Sample data

Get stratified (by year) data sample.

```{r}
set.seed(24)
data_sample <- np_data %>%
  group_by(year) %>%  # stratify by year
  sample_frac(0.01) %>%  # take 0.1 % from each category
  ungroup()
```

# Fit model with sampled data

Model 1: Fit a simple generalized linear model model with interaction of year and NP length and random intercepts for head noun lemma and author.

```{r}
# model 1: model with interaction and random intercepts
lm_uid_dev_1 <- lmerTest::lmer(uid_dev ~ year_c * NP_len
                           + head_synt_role_F
                           + (1|head_lemma)
                           + (1|author),
                           data = data_sample)
```

Perform model diagnostics.

```{r}
# AIC
AIC(lm_uid_dev_1)
# random effects variance
VarCorr(lm_uid_dev_1)
```
```{r}
# check residuals
sim_lm_uid_dev_1 <- DHARMa::simulateResiduals(lm_uid_dev_1)
DHARMa::plotQQunif(sim_lm_uid_dev_1) # create qq-plot
DHARMa::plotResiduals(sim_lm_uid_dev_1) # plot residuals against expected value
DHARMa::plotResiduals(sim_lm_uid_dev_1, form = data_sample$year_c) # plot residuals against predictor
```

Model 2: Fit a gamma model with an interaction of year and NP length and random intercepts for head noun lemma and author.

```{r}
# model 2: model with interaction and random intercepts
lm_uid_dev_2 <- glmmTMB::glmmTMB(uid_dev ~ year_c * NP_len
                           + head_synt_role_F
                           + (1|head_lemma)
                           + (1|author),
                           data = data_sample,
                           family=Gamma(link = "log"))
```

Perform model diagnostics.

```{r}
# AIC
AIC(lm_uid_dev_2)
# random effects variance
VarCorr(lm_uid_dev_2)
```

```{r}
# check residuals
sim_lm_uid_dev_2 <- DHARMa::simulateResiduals(lm_uid_dev_2)
DHARMa::plotQQunif(sim_lm_uid_dev_2) # create qq-plot
DHARMa::plotResiduals(sim_lm_uid_dev_2) # plot residuals against expected value
DHARMa::plotResiduals(sim_lm_uid_dev_2, form = data_sample$year_c) # plot residuals against predictor
```

Model 3: Fit model with
- predictor year
- interaction of average surprisal and number of constituents
- head syntactic role has control variable
- random intercepts for head lemma and author

```{r}
lm_uid_dev_3 <- glmmTMB::glmmTMB(uid_dev ~ year_c
                             + avg_srp_c * NP_len_c
                             + head_synt_role_F
                             + (1|head_lemma)
                             + (1|author),
                           family=Gamma(link = "log"),
                           data = data_sample)
```

Perform model diagnostics.

```{r}
# AIC
AIC(lm_uid_dev_3)
# random effects variance
VarCorr(lm_uid_dev_3)
# Variance Inflation Factor (collinearity)
performance::check_collinearity(lm_uid_dev_3)
```
Check residuals.

```{r}
# check residuals
sim_lm_uid_dev_3 <- DHARMa::simulateResiduals(lm_uid_dev_3)
DHARMa::plotQQunif(sim_lm_uid_dev_3) # create qq-plot
DHARMa::plotResiduals(sim_lm_uid_dev_3) # plot residuals against expected value
DHARMa::plotResiduals(sim_lm_uid_dev_3, form = data_sample$year_c) # plot residuals against predictor
```


## Cross-validation

# Sample data

Sample data for cross-validation (due to dataset being very large). Sample is stratified by year.

```{r}
set.seed(25)
data_sample_2 <- np_data %>%
  group_by(year) %>%  # stratify by year
  sample_frac(0.01) %>%  # take 1% from each category
  ungroup()
```

# Run Cross-Validation

Prepare parallelization.

```{r}
# use all available cores except one
future::plan(future::multisession, workers = parallel::detectCores() - 1)
```

Create 10 folds.

```{r}
set.seed(12)
# create 10 folds
folds <- rsample::vfold_cv(data_sample_2, v = 10)
```

Run cross-validation iteratively for each fold: Fit model with training data, then test with test data.

```{r}
results <- future.apply::future_lapply(
  folds$splits,
  function(split) {
    # select train and test data
    train <- rsample::analysis(split)
    test  <- rsample::assessment(split)
  
    #train$uid_dev_shift <- train$uid_dev + 0.0001 # small positive offset
    #test$uid_dev_shift <- test$uid_dev + 0.0001 # small positive offset
    
    # fit mixed-effects model
    fit <- glmmTMB::glmmTMB(uid_dev ~ year_c
                             + avg_srp_c * NP_len_c
                             + head_synt_role_F
                             + (1|head_lemma)
                             + (1|author),
                           family=Gamma(link = "log"),
                           data = train)
  
    # predict on test data
    preds <- predict(fit, newdata = test, allow.new.levels = TRUE)
  
    # compute error metrics
    # RMSE = Root Mean Squared Error
    # MAE = Mean Absolute Error
    dplyr::tibble(
      rmse = sqrt(mean((test$uid_dev - preds)^2)),
      mae  = mean(abs(test$uid_dev - preds))
    )
  },
  future.seed = TRUE,
  future.scheduling = 1,
  future.packages = c("lmerTest", "rsample", "dplyr")
)
```

Summarize the error metrics.

```{r}
cv_results <- dplyr::bind_rows(results)

cv_results %>%
  dplyr::summarise(
    mean_rmse = mean(rmse),
    mean_mae  = mean(mae)
  )
```

Save to file.

```{r}
# save error metrics to csv file
write.csv(cv_results, file = "C:/Users/isabell/Documents/UdS/Corpus_Analysis/RSC/fluctuation_complexity/results/20250820_uid_dev/cv_results.csv")
```


Plot the error metrics.

```{r}
ggplot(cv_results, aes(x = rmse)) +
  geom_histogram(bins = 6, fill = "steelblue", color = "white") +
  labs(title = "Distribution of RMSE across 10 folds", x = "RMSE", y = "Count")

ggplot(cv_results, aes(y = mae)) +
  geom_boxplot(fill = "tomato", alpha = 0.6) +
  labs(title = "Distribution of MAE across 10 folds", y = "MAE")
```

Fit model on all of the data.

```{r}
lm_uid_dev_final <- glmmTMB::glmmTMB(uid_dev ~ year_c
                             + avg_srp_c * NP_len_c
                             + head_synt_role_F
                             + (1|head_lemma)
                             + (1|author),
                           family=Gamma(link = "log"),
                           data=data_sample_2)
```
Model summary.

```{r}
summary(lm_uid_dev_final)
# write model summary to file
output <- capture.output(summary(lm_uid_dev_final))
cat("model_summary", output, file="C:/Users/isabell/Documents/UdS/Corpus_Analysis/RSC/fluctuation_complexity/results/20250820_uid_dev/model_summary.txt", sep="\n", append=TRUE)
```


## Visualization

Visualize the results of the models.

Model 1

```{r}
# plot effect of time
ggeffects::ggeffect(lm_sigma_1, c("year_c")) %>%
  plot() +
  labs(x = "Time",
       y = "Predicted Uniform Information Density (sigma gamma)",
       title = "")
# plot effect of NP length
ggeffects::ggeffect(lm_sigma_1, c("NP_len")) %>%
  plot() +
  labs(x = "Number of Constituents",
       y = "Predicted Uniform Information Density (sigma gamma)",
       title = "")
# plot effect of syntactic role
ggeffects::ggeffect(lm_sigma_1, c("head_synt_role_F")) %>%
  plot() +
  labs(x = "Head Syntactic Role",
       y = "Predicted Uniform Information Density (sigma gamma)",
       title = "")
```


```{r}
# plot effect of time
ggeffects::ggeffect(lm_uid_dev_2, c("year_c")) %>%
  plot() +
  labs(x = "Time",
       y = "Predicted Uniform Information Density (sigma gamma)",
       title = "")
# plot effect of NP length
ggeffects::ggeffect(lm_uid_dev_2, c("NP_len")) %>%
  plot() +
  labs(x = "Number of Constituents",
       y = "Predicted Uniform Information Density (sigma gamma)",
       title = "")
# plot effect of syntactic role
ggeffects::ggeffect(lm_uid_dev_2, c("head_synt_role_F")) %>%
  plot() +
  labs(x = "Head Syntactic Role",
       y = "Predicted Uniform Information Density (sigma gamma)",
       title = "")
```

Final Model.

```{r}
# function to center a concrete variable value
center_value <- function(data,column,x){
  mean_value = mean(data[[column]])
  (x - mean_value)
}

# calculate centered NP length values
center_value(data_sample_2,"NP_len",3)
center_value(data_sample_2,"NP_len",7)
center_value(data_sample_2,"NP_len",15)

# calculate centered average surprisal values
center_value(data_sample_2,"avg_srp",7.5)
center_value(data_sample_2,"avg_srp",10)
center_value(data_sample_2,"avg_srp",12.5)
```


```{r}
# plot effect of time
ggeffects::ggeffect(lm_uid_dev_final, c("year_c")) %>%
  plot() +
  labs(x = "Time (centered)",
       y = "Predicted UIDev",
       title = "")

# plot effect of NP length (version 1)
ggeffects::ggeffect(lm_uid_dev_final, c("avg_srp_c", "NP_len_c[-5.424059,-1.424059,6.575941]")) %>%
  plot() +
  labs(x = "Average Surprisal (centered)",
       y = "Predicted UIDev",
       title = "",
       color = "Const. Number") +
  scale_color_hue(labels = c("3", "7", "15"))

# plot effect of NP length (version 2)
ggeffects::ggeffect(lm_uid_dev_final, c("NP_len_c", "avg_srp_c[0.3173475,2.817347,5.317347]")) %>%
  plot() +
  labs(x = "NP Length (centered)",
       y = "Predicted UIDev",
       title = "",
       color = "Avg. Surprisal") +
  scale_x_continuous(limits=c(0,20)) +
  scale_y_continuous(limits=c(0,30)) +
  scale_color_hue(labels = c("7.5", "10", "12.5"))
```

